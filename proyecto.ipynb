{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/luisdi97/Proyecto_PF-3347/blob/main/proyecto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final Análisis en Ciencia de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estudiantes\n",
    "\n",
    "* Luis Diego Araya Campos\n",
    "* Cristian Alejandro Herrera Barboza\n",
    "* Josué Raúl Rivas Muñoz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Selección del Dataset\n",
    "Este dataset ha sido seleccionado debido a su relevancia en el contexto de la planificación energética y su aplicabilidad en la creciente adopción de energías renovables, especialmente la energía solar. Dado que uno de los integrantes del grupo tiene acceso a la información requerida, se analiza como una excelente opción la creación de un modelo de aprendizaje que permita optimizar procesos y ayudar en la toma de decisiones que podrían fomentar la eficiencia energética y la sostenibilidad en comunidades locales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Descripción del Problema\n",
    "\n",
    "### Contexto del problema\n",
    "En el contexto de la transición hacia energías renovables, como la solar, el análisis de la capacidad de instalación de paneles solares en distintos puntos de una red eléctrica es crucial para optimizar el consumo y la generación de energía sostenible. Sin embargo, esta capacidad no es uniforme y depende de varios factores de la red, tales como la capacidad del transformador, la carga actual en kVA, la distancia de los puntos de carga respecto a la subestación y al transformador, entre otros.\n",
    "\n",
    "Para determinar la viabilidad de la instalación de paneles solares, se realiza un estudio de capacidad de alojamiento mediante software especializado el cual arroja la capacidad de alojamiento para los distintos punto de la red, el cual define el límite máximo de generación que puede ser inyectada en la red sin comprometer la estabilidad del sistema ni exceder la capacidad de los componentes eléctricos, como transformadores y líneas de transmisión. Así, mediante algoritmos de aprendizaje se pretende predecir la máxima capacidad de alojamiento en kW que soportan las ubicaciones donde se pretende instalar un panel.\n",
    "\n",
    "#### Importancia:\n",
    "Resolver este problema tiene un impacto directo en la capacidad de planificación y expansión de infraestructuras de energías renovables. Al predecir las capacidades de alojamiento mediante un modelo de aprendizaje se puede agilizar el proceso ya que realizar el mismo cálculo mediante el software especializado puede tardar incluso varios días para los circuitos más grandes, de esta forma también se agiliza la planificación de la red al mostrar los puntos donde podría crecer la generación distribuida y en qué medida.\n",
    "Por otro lado al permitir la integración de paneles solares de forma segura y óptima reduce la huella de carbono y promueve un uso más ecológico de los recursos eléctricos esto a mismo tiempo que se optimizan los sistemas actuales.\n",
    "\n",
    "#### Objetivo del Análisis\n",
    "El objetivo de este análisis es desarrollar un modelo predictivo que estime la capacidad de alojamiento para las distintas ubicaciones en la red en función de variables clave. Este modelo permitirá determinar la capacidad de instalación de paneles solares en cada nodo de carga, facilitando así la toma de decisiones informadas sobre la incorporación de fuentes de energía renovable en cada punto de la red. Al optimizar la asignación de estas instalaciones, se espera que se logren beneficios económicos y ambientales significativos, ayudando a reducir la dependencia de fuentes de energía no renovables y mejorando la eficiencia de la red eléctrica.\n",
    "\n",
    "#### Supuestos iniciales\n",
    "De los circuitos de la red eléctrica con datos disponibles para armar el dataset se eligieron aquellos donde no había reguladores o plantas grandes de generación privada, de manera que se simplifica el problema a resolver. Por otro lado, como se muestra en el preprocesamiento del dataset se eliminan las instancias que tienen asociados transformadores grandes o que presentaran generación distribuida por lo cual se espera que hayan pocos o ningunos outliers. De esta forma se espera que el dataset sea de baja dificultad logrando que los modelos se sintonizen de manera sencilla y presenten buenas métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocesamiento del Dataset\n",
    "Se realiza un preprocesamiento para asegurar la consistencia, relevancia y calidad de la información, se agrega una columna extra donde se realiza un conteo del número de entradas por circuito lo cual representa el número de clientes monofásicos del circuito y da una idea del tamaño del circuito que es un aspecto que afecta los resultados del análisis de capacidad de alojamiento, para ello se agrupan las instancias por el identificador de la red (Network Id).\n",
    "Se seleccionaron únicamente las filas donde la generación distribuida es igual a 0.0, es decir, aquellas sin generación adicional en las cargas para simplificar el modelo ya que si ya existe generación distribuida en el punto la generación adicional arrojada por el software especializado es menor.\n",
    "Además se deben filtrar las filas para excluir cualquier valor de carga negativo o inválido ('Load (kVA)' >= 0.0). Esto garantiza que solo se consideren valores positivos y realistas de carga, lo que mejora la precisión del modelo.\n",
    "Como dato adicional es importante restringir el dataset a transformadores con una capacidad máxima de 50 kVA, para centrar el análisis en transformadores de menor capacidad, típicos de instalaciones residenciales o comerciales pequeñas. Este enfoque asegura que el modelo se optimice para escenarios en los que la carga y la capacidad son limitadas, ya que los de mayor capacidad pueden generar ruido en los datos y bajar la precisión del modelo.\n",
    "Las features más relevantes seleccionadas permiten mejorar los resultados, incluyendo capacidad del transformador, impedancia, carga en kVA, número de nodos de carga, y distancias de conexión (del punto a la subestación y del punto al transformador). Estas variables permiten al modelo aprender patrones importantes para la predicción de la capacidad de carga de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datos_IA_ICA.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.copy()\n",
    "\n",
    "# Se agrega una columna nueva con el número de datos por circuito\n",
    "df_final['Num_Nodos_Load'] = df_final.groupby('Network Id')['Network Id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se seleccionan solo las instancias donde no hay generación distribuida\n",
    "df_final = df_final.loc[df_final['Distributed Generation per Load (kW)'] == 0.0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se seleccionan solo las instancias donde la carga es positiva\n",
    "df_final = df_final.loc[df_final['Load (kVA)'] >= 0.0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se imprimen los valores de capacidad de trasformadores\n",
    "kVA_transformers = list(df_final['Transformer Capacity (kVA)'].unique())\n",
    "kVA_transformers.sort()\n",
    "kVA_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se seleccionan solo las instancias con transformador de capacidad menor o igual a 50 kVA, para evitar outliers\n",
    "df_final = df_final.loc[df_final['Transformer Capacity (kVA)'] <= 50.0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifico que no hayan valores nulos, en las columnas que se utilizarán para el análisis:\n",
    "print(\n",
    "    df_final[\n",
    "        [\n",
    "            'Transformer Capacity (kVA)',\n",
    "            'Total Path Z (Ω)',\n",
    "            'Load (kVA)',\n",
    "            'Number of Load Nodes',\n",
    "            'Distance from substation to Load (m)',\n",
    "            'Distance from transformer to Load (m)',\n",
    "            'Num_Nodos_Load','IC Max per Load (kW)',\n",
    "        ]\n",
    "    ].isnull().sum()\n",
    ")\n",
    "\n",
    "duplicated_rows = df_final.duplicated()\n",
    "# Mostrar todas las filas duplicadas si existen\n",
    "df_final[duplicated_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se imprime la descrición de los datos con los que contamos\n",
    "df_final.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se imprime el dataset\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definen los features y el target\n",
    "\n",
    "features = [\n",
    "    'Transformer Capacity (kVA)',\n",
    "    'Total Path Z (Ω)',\n",
    "    'Load (kVA)',\n",
    "    'Number of Load Nodes',\n",
    "    'Distance from substation to Load (m)',\n",
    "    'Distance from transformer to Load (m)',\n",
    "    'Num_Nodos_Load',\n",
    "]\n",
    "\n",
    "target = 'IC Max per Load (kW)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuando con el preprosesamiento de los datos, se aplica un algoritmo de detección de anomalías basado en árboles de decisión llamado Isolation Forest. El objetivo es es identificar datos atípicos mediante la partición iterativa del espacio de características, este algoritm funciona aislando puntos de datos utilizando divisiones aleatorias y midiendo la profundidad promedio de estas particiones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimo la media:\n",
    "df_num_features = df_final[['Transformer Capacity (kVA)',\n",
    "            'Total Path Z (Ω)',\n",
    "            'Load (kVA)',\n",
    "            'Number of Load Nodes',\n",
    "            'Distance from substation to Load (m)',\n",
    "            'Distance from transformer to Load (m)',\n",
    "            'Num_Nodos_Load','IC Max per Load (kW)'\n",
    "            ]]\n",
    "mean_values_selected = df_num_features.mean()\n",
    "\n",
    "print(mean_values_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "iso = IsolationForest(contamination=0.05)  # 5% de anomalías esperadas\n",
    "anomaly_labels = iso.fit_predict(df_num_features)\n",
    "\n",
    "# Filtrar anomalías\n",
    "anomalies = df_num_features[anomaly_labels == -1]\n",
    "print(anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este preprocesamiento arrojó un total de 3944 resultados, pero al compararlos con la media, en realidad son datos que se alejan un poco de la media, pero siguen siendo valores importantes para el entrenamiento, por lo que se decide no excluirlos del dataset y continuar con el entrenamiento haciendo uso de los mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Con los valores obtenidos y para un mejor análisis se crea una matriz de correlación\n",
    "# Crear una matriz de correlación\n",
    "correlacion = df_final[[\n",
    "    'Transformer Capacity (kVA)',\n",
    "    'Total Path Z (Ω)',\n",
    "    'Load (kVA)',\n",
    "    'Number of Load Nodes',\n",
    "    'Distance from substation to Load (m)',\n",
    "    'Distance from transformer to Load (m)',\n",
    "    'Num_Nodos_Load',\n",
    "    'IC Max per Load (kW)'\n",
    "]].corr()\n",
    "\n",
    "# Visualizar la matriz de correlación\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlacion, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Matriz de Correlación')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general las correlaciones son bajas por lo que todos los features son relevantes para la creación del modelo de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definen las entradas y salidas para entrenar y probar los modelos\n",
    "X = df_final.loc[:, features].copy()\n",
    "y = df_final.loc[:, target].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de implementación de algoritmo de regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Separación de subconjuntos para entrenamiento y pruebas.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros iniciales\n",
    "\n",
    "params_svr = {\n",
    "    # epsilon=0.0,\n",
    "    # tol=0.0001,\n",
    "    # C=1.0,\n",
    "    # loss='epsilon_insensitive',\n",
    "    # fit_intercept=True,\n",
    "    # intercept_scaling=1.0,\n",
    "    # dual='auto',\n",
    "    # verbose=0,\n",
    "    # random_state=None,\n",
    "    # max_iter=1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "linear_reg = LinearSVR(**params_svr)\n",
    "\n",
    "# Entrenar el modelo\n",
    "linear_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar predicciones\n",
    "y_pred_linear = linear_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular las métricas\n",
    "mse = mean_squared_error(y_test, y_pred_linear)\n",
    "rmse = root_mean_squared_error(y_test, y_pred_linear)\n",
    "r2 = r2_score(y_test, y_pred_linear)\n",
    "\n",
    "# Obtener el Training Score (R² en el conjunto de entrenamiento)\n",
    "train_score = linear_reg.score(X_train, y_train)\n",
    "\n",
    "# Obtener el Testing Score (R² en el conjunto de prueba)\n",
    "test_score = linear_reg.score(X_test, y_test)\n",
    "\n",
    "# Calculo del MAE\n",
    "mae_linear = mean_absolute_error(y_test, y_pred_linear)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "print(f\"Training Score (R²): {train_score}\")\n",
    "print(f\"Testing Score (R²): {test_score}\")\n",
    "print(f\"MAE: {mae_linear}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada la forma de los datos utilizados, al utilizar un kernel lineal para la regresión, el algoritmo es incapaz de converger correctamente y dar valores de error y puntuaciones safistactorias. De hecho se puede notar en la celda anterior que estas métricas son bastante malas, aún haciendo pruebas con otros hiper-parámetros en el algortimo.\n",
    "\n",
    "Por esta razón, a continuación se exploran diferentes algoritmos no lineales que logren mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba inicial para KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para el uso de KNN es necesario normalizar las características:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División del dataset en entrenamiento y prueba para KNN. Es diferente de los demás algoritmos, ya que en este se usa el X escalado\n",
    "X_train_knn, X_test_knn, y_train_knn, y_test_knn = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verificar los tamaños de los conjuntos\n",
    "print(f\"Conjunto de entrenamiento: {X_train_knn.shape}\")\n",
    "print(f\"Conjunto de prueba: {X_test_knn.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo KNN\n",
    "knn = KNeighborsRegressor(n_neighbors=5)  # Este es el hiperparámetro que se ajusta en KNN idealmente inicia en 5\n",
    "\n",
    "# Entrenar el modelo\n",
    "knn.fit(X_train_knn, y_train_knn)\n",
    "\n",
    "# Realizar predicciones\n",
    "knn_y_pred = knn.predict(X_test_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de las métricas\n",
    "mse_knn = mean_squared_error(y_test_knn, knn_y_pred)\n",
    "rmse_knn = root_mean_squared_error(y_test_knn, knn_y_pred)\n",
    "r2_knn = r2_score(y_test_knn, knn_y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse_knn}')\n",
    "print(f'Root Mean Squared Error: {rmse_knn}')\n",
    "print(f'R^2 Score: {r2_knn}')\n",
    "\n",
    "# Obtener el Training Score (R² en el conjunto de entrenamiento)\n",
    "train_score_knn = knn.score(X_train_knn, y_train_knn)\n",
    "\n",
    "# Obtener el Testing Score (R² en el conjunto de prueba)\n",
    "test_score_knn = knn.score(X_test_knn, y_test_knn)\n",
    "\n",
    "# Calculo del MAE\n",
    "mae_knn = mean_absolute_error(y_test_knn, knn_y_pred)\n",
    "\n",
    "print(f\"Training Score (R²): {train_score_knn}\")\n",
    "print(f\"Testing Score (R²): {test_score_knn}\")\n",
    "\n",
    "print(f\"MAE: {mae_knn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización de los hiperparámetros\n",
    "Se determina que deben haber mejores hiperparámetros, por lo que se intenta revisar cual es el mejor numero de vecinos (n_neighbors). Para esto se hace un análisis desde 1 hasta 21:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# Probar diferentes valores de n_neighbors\n",
    "for k in range(1, 21):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    # Realizar cross-validation con 5 particiones (cv=5)\n",
    "    cv_scores = cross_val_score(knn, X_train_knn, y_train_knn, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    knn.fit(X_train_knn, y_train_knn)\n",
    "    # Obtener el Training Score (R² en el conjunto de entrenamiento)\n",
    "    train_scores.append(knn.score(X_train_knn, y_train_knn))\n",
    "\n",
    "    # Obtener el Testing Score (R² en el conjunto de prueba)\n",
    "    test_scores.append(knn.score(X_test_knn, y_test_knn))\n",
    "\n",
    "    # Calcular el puntaje promedio (usar negativo porque cross_val_score devuelve errores negativos)\n",
    "    scores.append(-1*np.mean(cv_scores))\n",
    "\n",
    "# Encontrar el valor de n_neighbors con el menor error\n",
    "best_k = np.argmin(scores) + 1\n",
    "print(f\"Mejor valor de n_neighbors: {best_k}\")\n",
    "\n",
    "# Graficar los puntajes\n",
    "plt.plot(range(1, 21), scores)\n",
    "plt.xlabel('Número de vecinos (n_neighbors)')\n",
    "plt.ylabel('Error promedio (RMSE)')\n",
    "plt.title('Número de vecinos vs. Error')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 21), train_scores, label='Training Score (R²)', color='blue', marker='o')\n",
    "plt.plot(range(1, 21), test_scores, label='Testing Score (R²)', color='green', marker='o')\n",
    "\n",
    "# Añadir etiquetas y título\n",
    "plt.xlabel('Número de vecinos (n_neighbors)')\n",
    "plt.ylabel('Puntaje R²')\n",
    "plt.title('Training vs Testing Score en relación a n_neighbors')\n",
    "\n",
    "# Añadir la leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se harán pruebas variando otros hiperámetros del algoritmo, en especial la función de pesos usada en la predicción.\n",
    "El valor defaul es \"uniform\". Ahora se probará con \"distance\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=3, weights='distance')  # Se ajusta el hiperparámetro \"weights\" para ver las diferencias.\n",
    "\n",
    "knn.fit(X_train_knn, y_train_knn)\n",
    "\n",
    "knn_y_pred = knn.predict(X_test_knn)\n",
    "\n",
    "mse = mean_squared_error(y_test_knn, knn_y_pred)\n",
    "rmse = root_mean_squared_error(y_test_knn, knn_y_pred)\n",
    "r2 = r2_score(y_test_knn, knn_y_pred)\n",
    "\n",
    "# Obtener el Training Score (R² en el conjunto de entrenamiento)\n",
    "train_score = knn.score(X_train_knn, y_train_knn)\n",
    "# Obtener el Testing Score (R² en el conjunto de prueba)\n",
    "test_score = knn.score(X_test_knn, y_test_knn)\n",
    "# Calculo del MAE\n",
    "mae_knn = mean_absolute_error(y_test_knn, knn_y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "print(f\"Training Score (R²): {train_score}\")\n",
    "print(f\"Testing Score (R²): {test_score}\")\n",
    "print(f\"MAE: {mae_knn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como los resultados muestran un claro overfitting para la puntuación de entranamiento, se desecha la idea de utilizar la función \"distance\" para el cálculo de pesos y se retorna al valor default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medición de Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado del análisis indica que el mejor numero de vecinos es 3, por lo que se ejecuta el algoritmo con este valor y se vuelven a imprimir las metricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "tracemalloc.start()\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=3)  # Este es el hiperparámetro que se ajusta en KNN idealmente inicia en 5\n",
    "\n",
    "# Ajusto los modelos a funciones, esto con el fin de poder obtener un tiempo de ejecución tanto para el entrenamiento como para la predicción\n",
    "# Entrenar el modelo\n",
    "def train_model():\n",
    "    knn.fit(X_train_knn, y_train_knn)\n",
    "\n",
    "# Realizar predicciones\n",
    "def predict_model():\n",
    "    global knn_y_pred_t\n",
    "    knn_y_pred_t = knn.predict(X_test_knn)\n",
    "\n",
    "train_time_knn = timeit.timeit(train_model, number=1)\n",
    "print(f\"Tiempo de entrenamiento: {train_time_knn:.2f} segundos\")\n",
    "\n",
    "predict_time_knn = timeit.timeit(predict_model, number=1)\n",
    "print(f\"Tiempo de predicción: {predict_time_knn:.2f} segundos\")\n",
    "\n",
    "memoria_knn, peak_knn = tracemalloc.get_traced_memory()\n",
    "print(f\"Uso de memoria actual: {memoria_knn / 10**6:.2f} MB\")\n",
    "print(f\"Pico de uso de memoria: {peak_knn / 10**6:.2f} MB\")\n",
    "tracemalloc.stop()\n",
    "\n",
    "mse_knn_final = mean_squared_error(y_test_knn, knn_y_pred_t)\n",
    "rmse_knn_final = root_mean_squared_error(y_test_knn, knn_y_pred_t)\n",
    "r2_knn_final = r2_score(y_test_knn, knn_y_pred_t)\n",
    "\n",
    "# Obtener el Training Score (R² en el conjunto de entrenamiento)\n",
    "train_score_knn_final = knn.score(X_train_knn, y_train_knn)\n",
    "# Obtener el Testing Score (R² en el conjunto de prueba)\n",
    "test_score_knn_final = knn.score(X_test_knn, y_test_knn)\n",
    "# Calculo del MAE\n",
    "mae_knn_final = mean_absolute_error(y_test_knn, knn_y_pred_t)\n",
    "\n",
    "print(f'Mean Squared Error: {mse_knn_final}')\n",
    "print(f'Root Mean Squared Error: {rmse_knn_final}')\n",
    "print(f'R^2 Score: {r2_knn_final}')\n",
    "print(f\"Training Score (R²): {train_score_knn_final}\")\n",
    "print(f\"Testing Score (R²): {test_score_knn_final}\")\n",
    "print(f\"MAE: {mae_knn_final}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con los datos obtenidos se imprimen los resultados:\n",
    "# Valores de R²\n",
    "scores = [train_score_knn_final, test_score_knn_final]\n",
    "labels = ['Training Score', 'Testing Score']\n",
    "\n",
    "# Convertir a porcentaje\n",
    "scores_percentage = [score * 100 for score in scores]\n",
    "\n",
    "# Crear gráfico de barras\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(labels, scores_percentage, color=['blue', 'orange'])\n",
    "plt.ylim(0, 100)  # Rango de porcentaje\n",
    "plt.ylabel('R² Score (%)')\n",
    "plt.title('Comparación de R² Scores')\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "\n",
    "# Formatear etiquetas en el eje y como porcentaje\n",
    "plt.yticks(ticks=np.arange(0, 101, 10), labels=[f'{int(tick)}%' for tick in np.arange(0, 101, 10)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se realiza un análisis de la predicción de los valores:\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_knn, knn_y_pred_t, alpha=0.7)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Predicciones vs Valores Reales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento para los demás modelos.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba inicial para Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se calculan las metricas del Random Forest.\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = root_mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Obtener el Training Score (R² en el conjunto de entrenamiento)\n",
    "train_score_rf = rf.score(X_train, y_train)\n",
    "\n",
    "# Obtener el Testing Score (R² en el conjunto de prueba)\n",
    "test_score_rf = rf.score(X_test, y_test)\n",
    "\n",
    "# Calculo del MAE\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f'Mean Squared Error: {mse_rf}')\n",
    "print(f'Root Mean Squared Error: {rmse_rf}')\n",
    "print(f'R^2 Score: {r2_rf}')\n",
    "print(f\"Training Score (R²): {train_score_rf}\")\n",
    "print(f\"Testing Score (R²): {test_score_rf}\")\n",
    "print(f\"MAE: {mae_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización de los Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se probarán diferentes valores de n_estimators para encontrar el óptimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "scores = []\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "range_test = range(95, 117, 1)\n",
    "\n",
    "# Probar diferentes valores de n_estimators\n",
    "for n in range_test:\n",
    "    rf = RandomForestRegressor(n_estimators=n, max_depth=15)\n",
    "\n",
    "    # Realizar cross-validation con 5 particiones (cv=5)\n",
    "    cv_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    # Obtener el Training Score (R² en el conjunto de entrenamiento)\n",
    "    train_scores.append(rf.score(X_train, y_train))\n",
    "\n",
    "    # Obtener el Testing Score (R² en el conjunto de prueba)\n",
    "    test_scores.append(rf.score(X_test, y_test))\n",
    "\n",
    "    # Calcular el puntaje promedio (usar negativo porque cross_val_score devuelve errores negativos)\n",
    "    scores.append(-1*np.mean(cv_scores))\n",
    "\n",
    "# Encontrar el valor de n_estimators con el menor error\n",
    "best_n = 10 + np.argmin(scores)*38\n",
    "print(f\"Mejor valor de n_estimators: {best_n}\")\n",
    "\n",
    "# Graficar los puntajes\n",
    "plt.plot(range_test, scores)\n",
    "plt.xlabel('Número de estimadores (n_estimators)')\n",
    "plt.ylabel('Error promedio (RMSE)')\n",
    "plt.title('Número de estimadores vs. Error')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range_test, train_scores, label='Training Score (R²)', color='blue', marker='o')\n",
    "plt.plot(range_test, test_scores, label='Testing Score (R²)', color='green', marker='o')\n",
    "\n",
    "# Añadir etiquetas y título\n",
    "plt.xlabel('Número de estimadores (n_estimators)')\n",
    "plt.ylabel('Puntaje R²')\n",
    "plt.title('Training vs Testing Score en relación a n_estimators')\n",
    "\n",
    "# Añadir la leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mejorar los resultados se realiza una busqueda de Grid Search para encontrar los mejores parámetros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejores parámetros encontrados: {'n_estimators': 184, 'max_depth': 48, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
    "\n",
    "# Definir los parámetros a probar\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42) # n_estimators=10 da un muy buen resultado ;Mean Squared Error (Random Forest): 40.11068269701386 y R² Score (Random Forest): 0.902790660423813\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=10,\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado del Grid Search indica:\n",
    "Mejores parámetros encontrados: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
    "Por lo que se ejecuta el algoritmo con dichos parámetros\n",
    "\n",
    "Como siguiete paso después del grid search se implementa una busqueda de parámetros con una optimización Bayesiana, esto con el objetivo de comparar los resultados obtenidos con el grid search y encontrar aún mejores hiper parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Definir el espacio de búsqueda\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_categorical('max_depth', [None] + list(range(1, 51)))\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    max_features = trial.suggest_categorical('max_features', [None, 'sqrt', 'log2'])\n",
    "\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Validación cruzada\n",
    "    scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "    return -scores.mean()\n",
    "\n",
    "# Ejecutar la optimización\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los mejores parámetros\n",
    "print(\"Mejores parámetros encontrados:\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La búsqueda Vayeciana da como resultado los siguientes parámetros a utilizar :\n",
    "Mejores parámetros encontrados: {'n_estimators': 184, 'max_depth': 48, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
    "Luego se procede a ejecutar tanto con los parámetros encontrados por la busqueda bayeciana, como por gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestRegressor(\n",
    "    max_depth=None,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "def train_model():\n",
    "    best_rf.fit(X_train, y_train)\n",
    "\n",
    "def predict_model():\n",
    "    global y_pred_grid_rf\n",
    "    y_pred_grid_rf = best_rf.predict(X_test)\n",
    "\n",
    "train_time_grid_rf = timeit.timeit(train_model, number=1)\n",
    "print(f\"Tiempo de entrenamiento: {train_time_grid_rf:.2f} segundos\")\n",
    "\n",
    "predict_time_grid_rf = timeit.timeit(predict_model, number=1)\n",
    "print(f\"Tiempo de predicción: {predict_time_grid_rf:.2f} segundos\")\n",
    "\n",
    "# Evaluar el modelo\n",
    "mse_grid_rf = mean_squared_error(y_test, y_pred_grid_rf)\n",
    "rmse_grid_rf = root_mean_squared_error(y_test, y_pred_grid_rf)\n",
    "r2_grid_rf = r2_score(y_test, y_pred_grid_rf)\n",
    "\n",
    "train_score_grid_rf = best_rf.score(X_train, y_train)\n",
    "\n",
    "test_score_grid_rf = best_rf.score(X_test, y_test)\n",
    "\n",
    "mae_grid_rf = mean_absolute_error(y_test, y_pred_grid_rf)\n",
    "print(f'Mean Squared Error (Mejor Random Forest): {mse_grid_rf}')\n",
    "print(f'Root Mean Squared Error (Mejor Random Forest): {rmse_grid_rf}')\n",
    "print(f'R² Score (Mejor Random Forest): {r2_grid_rf}')\n",
    "print(f\"Training Score (R²): {train_score_grid_rf}\")\n",
    "print(f\"Testing Score (R²): {test_score_grid_rf}\")\n",
    "print(f\"MAE: {mae_grid_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejores parámetros encontrados: con busqueda bayeciana {'n_estimators': 184, 'max_depth': 48, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
    "\n",
    "bayeciana_rf = RandomForestRegressor(\n",
    "    max_depth=48,\n",
    "    max_features='log2',\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=185,\n",
    "    random_state=42\n",
    ")\n",
    "def train_model():\n",
    "    bayeciana_rf.fit(X_train, y_train)\n",
    "\n",
    "def predict_model():\n",
    "    global y_pred_bayeciana_rf\n",
    "    y_pred_bayeciana_rf = bayeciana_rf.predict(X_test)\n",
    "\n",
    "train_time_bayeciana_rf = timeit.timeit(train_model, number=1)\n",
    "print(f\"Tiempo de entrenamiento: {train_time_bayeciana_rf:.2f} segundos\")\n",
    "\n",
    "predict_time_bayeciana_rf = timeit.timeit(predict_model, number=1)\n",
    "print(f\"Tiempo de predicción: {predict_time_bayeciana_rf:.2f} segundos\")\n",
    "\n",
    "# Evaluar el modelo\n",
    "mse_bayeciana_rf = mean_squared_error(y_test, y_pred_bayeciana_rf)\n",
    "rmse_bayeciana_rf = root_mean_squared_error(y_test, y_pred_bayeciana_rf)\n",
    "r2_bayeciana_rf = r2_score(y_test, y_pred_bayeciana_rf)\n",
    "\n",
    "train_score_bayeciana_rf = bayeciana_rf.score(X_train, y_train)\n",
    "\n",
    "test_score_bayeciana_rf = bayeciana_rf.score(X_test, y_test)\n",
    "\n",
    "mae_bayeciana_rf = mean_absolute_error(y_test, y_pred_bayeciana_rf)\n",
    "print(f'Mean Squared Error (Mejor Random Forest): {mse_bayeciana_rf}')\n",
    "print(f'Root Mean Squared Error (Mejor Random Forest): {rmse_bayeciana_rf}')\n",
    "print(f'R² Score (Mejor Random Forest): {r2_bayeciana_rf}')\n",
    "print(f\"Training Score (R²): {train_score_bayeciana_rf}\")\n",
    "print(f\"Testing Score (R²): {test_score_bayeciana_rf}\")\n",
    "print(f\"MAE: {mae_bayeciana_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los valores del gridsearV se tiene como resultados:\n",
    "Mean Squared Error (Mejor Random Forest): 5.95865748121562\n",
    "Root Mean Squared Error (Mejor Random Forest): 2.4410361491005452\n",
    "R² Score (Mejor Random Forest): 0.8716450820359779\n",
    "Training Score (R²): 0.981951084216809\n",
    "Testing Score (R²): 0.8716450820359779\n",
    "MAE: 1.3488703394791421\n",
    "\n",
    "\n",
    "Con la optimización Bayesiana:\n",
    "\n",
    "Mean Squared Error (Mejor Random Forest): 5.95804402115964\n",
    "Root Mean Squared Error (Mejor Random Forest): 2.440910490198205\n",
    "R² Score (Mejor Random Forest): 0.8716582965252161\n",
    "Training Score (R²): 0.981925068435337\n",
    "Testing Score (R²): 0.8716582965252161\n",
    "MAE: 1.348832000941697\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de puntajes\n",
    "scores = {\n",
    "    \"Estimators=100\": [train_score_rf, test_score_rf],\n",
    "    \"GridSearch\": [train_score_grid_rf, test_score_grid_rf],\n",
    "    \"Bayesian Search\": [train_score_bayeciana_rf, test_score_bayeciana_rf],\n",
    "}\n",
    "\n",
    "# Convertir los datos en formato para graficar\n",
    "labels = list(scores.keys())  # Modelos\n",
    "train_scores = [score[0] for score in scores.values()]  # Train scores\n",
    "test_scores = [score[1] for score in scores.values()]  # Test scores\n",
    "\n",
    "# Configuración del gráfico\n",
    "x = np.arange(len(labels))  # Posiciones en el eje X\n",
    "width = 0.35  # Ancho de las barras\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Barras de train_score\n",
    "bars1 = ax.bar(x - width/2, train_scores, width, label='Train Score', color='blue')\n",
    "\n",
    "# Barras de test_score\n",
    "bars2 = ax.bar(x + width/2, test_scores, width, label='Test Score', color='orange')\n",
    "\n",
    "# Etiquetas y título\n",
    "ax.set_xlabel('Modelos', fontsize=12)\n",
    "ax.set_ylabel('Scores (R²)', fontsize=12)\n",
    "ax.set_title('Comparación de Scores Random Forest: estimators=100 vs GridSearch vs Búsqueda Bayesiana', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# Agregar valores encima de las barras\n",
    "for bar in bars1 + bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.2f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),  # Desplazamiento del texto\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de RMSE\n",
    "models = ['Random Forest', 'GridSearch', 'Bayesian Search']\n",
    "rmse_values = [rmse_rf, rmse_grid_rf, rmse_bayeciana_rf]\n",
    "\n",
    "# Crear el gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(models, rmse_values, color=['blue', 'orange', 'green'], alpha=0.8)\n",
    "\n",
    "# Agregar etiquetas y título\n",
    "plt.xlabel('Modelos', fontsize=12)\n",
    "plt.ylabel('RMSE', fontsize=12)\n",
    "plt.title('Comparación de RMSE en Random Forest: estimators=100 vs GridSearch vs Búsqueda Bayesiana', fontsize=14)\n",
    "\n",
    "# Mostrar valores encima de las barras\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height, f'{height:.2f}', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medición de Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este análisis permite determinar, que apesar de que se hizo una búsqueda exaustiva de los mejores hiperparámetros, la configuración por defecto cambiando unicamente a 100 n_estimators es la que mejores resultados ofrece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafican los resultados obtenidos para knn\n",
    "# Valores de R²\n",
    "scores = [train_score_rf, test_score_rf]\n",
    "labels = ['Training Score', 'Testing Score']\n",
    "\n",
    "# Convertir a porcentaje\n",
    "scores_percentage = [score * 100 for score in scores]\n",
    "\n",
    "# Crear gráfico de barras\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(labels, scores_percentage, color=['blue', 'orange'])\n",
    "plt.ylim(0, 100)  # Rango de porcentaje\n",
    "plt.ylabel('R² Score (%)')\n",
    "plt.title('Comparación de R² Scores KNN')\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "\n",
    "# Formatear etiquetas en el eje y como porcentaje\n",
    "plt.yticks(ticks=np.arange(0, 101, 10), labels=[f'{int(tick)}%' for tick in np.arange(0, 101, 10)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la gráfica\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.7, color='b', label='Predicciones')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, label='Limite de decisión')\n",
    "\n",
    "# Etiquetas y título\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Predicciones vs Valores Reales (Random Forest)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se analiza la importancia de las caracteristicas en Random Forest:\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Importancia de Características (Random Forest)')\n",
    "plt.bar(range(X.shape[1]), importances[indices], align='center')\n",
    "plt.xticks(range(X.shape[1]), np.array(X.columns)[indices], rotation=90)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba inicial para GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros iniciales\n",
    "\n",
    "params = {\n",
    "    # \"loss\": \"squared_error\",\n",
    "    # \"learning_rate\": 0.1,\n",
    "    # \"n_estimators\": 100,\n",
    "    # \"subsample\": 1.0,\n",
    "    # \"criterion\": \"friedman_mse\",\n",
    "    # \"min_samples_split\": 2,\n",
    "    # \"min_samples_leaf\": 1,\n",
    "    # \"min_weight_fraction_leaf\": 0.0,\n",
    "    # \"max_depth\": 3,\n",
    "    # \"min_impurity_decrease\": 0.0,\n",
    "    # \"init\": None,\n",
    "    \"random_state\": 42,\n",
    "    # \"max_features\": None,\n",
    "    # \"alpha\": 0.9,\n",
    "    # \"verbose\": 0,\n",
    "    # \"max_leaf_nodes\": None,\n",
    "    # \"warm_start\": False,\n",
    "    # \"validation_fraction\": 0.1,\n",
    "    # \"n_iter_no_change\": None,\n",
    "    # \"tol\": 0.0001,\n",
    "    # \"ccp_alpha\": 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "reg = GradientBoostingRegressor(**params)\n",
    "\n",
    "# Entrenar el modelo\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_gbr = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular las métricas\n",
    "mse = mean_squared_error(y_test, y_pred_gbr)\n",
    "rmse = root_mean_squared_error(y_test, y_pred_gbr)\n",
    "r2 = r2_score(y_test, y_pred_gbr)\n",
    "\n",
    "# Obtener el Training Score (R² en el conjunto de entrenamiento)\n",
    "train_score = reg.score(X_train, y_train)\n",
    "\n",
    "# Obtener el Testing Score (R² en el conjunto de prueba)\n",
    "test_score = reg.score(X_test, y_test)\n",
    "\n",
    "# Calculo del MAE\n",
    "mae_gbr = mean_absolute_error(y_test, y_pred_gbr)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "print(f\"Training Score (R²): {train_score}\")\n",
    "print(f\"Testing Score (R²): {test_score}\")\n",
    "print(f\"MAE: {mae_gbr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización de los hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "range_test = range(10, 1036, 38)\n",
    "\n",
    "# Probar diferentes valores de n_estimators\n",
    "for n in range_test:\n",
    "    grb = GradientBoostingRegressor(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=n,\n",
    "        min_samples_split=600,\n",
    "        min_samples_leaf=60,\n",
    "        max_depth=5,\n",
    "        random_state=42,\n",
    "        max_features='sqrt',\n",
    "    )\n",
    "    # Realizar cross-validation con 5 particiones (cv=5)\n",
    "    cv_scores = cross_val_score(grb, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    grb.fit(X_train, y_train)\n",
    "    # Obtener el Training Score (R² en el conjunto de entrenamiento)\n",
    "    train_scores.append(grb.score(X_train, y_train))\n",
    "\n",
    "    # Obtener el Testing Score (R² en el conjunto de prueba)\n",
    "    test_scores.append(grb.score(X_test, y_test))\n",
    "\n",
    "    # Calcular el puntaje promedio (usar negativo porque cross_val_score devuelve errores negativos)\n",
    "    scores.append(-1*np.mean(cv_scores))\n",
    "\n",
    "# Encontrar el valor de n_estimators con el menor error\n",
    "best_n = 10 + np.argmin(scores)*38\n",
    "print(f\"Mejor valor de n_estimators: {best_n}\")\n",
    "\n",
    "# Graficar los puntajes\n",
    "plt.plot(range_test, scores)\n",
    "plt.xlabel('Número de estimadores (n_estimators)')\n",
    "plt.ylabel('Error promedio (RMSE)')\n",
    "plt.title('Número de estimadores vs. Error')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range_test, train_scores, label='Training Score (R²)', color='blue', marker='o')\n",
    "plt.plot(range_test, test_scores, label='Testing Score (R²)', color='green', marker='o')\n",
    "\n",
    "# Añadir etiquetas y título\n",
    "plt.xlabel('Número de estimadores (n_estimators)')\n",
    "plt.ylabel('Puntaje R²')\n",
    "plt.title('Training vs Testing Score en relación a n_estimators')\n",
    "\n",
    "# Añadir la leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "range_test = range(2, 1271, 47)\n",
    "\n",
    "# Probar diferentes valores de min_samples_split\n",
    "for n in range_test:\n",
    "    grb = GradientBoostingRegressor(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        min_samples_split=n,\n",
    "        min_samples_leaf=60,\n",
    "        max_depth=5,\n",
    "        random_state=42,\n",
    "        max_features='sqrt',\n",
    "    )\n",
    "    # Realizar cross-validation con 5 particiones (cv=5)\n",
    "    cv_scores = cross_val_score(grb, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    grb.fit(X_train, y_train)\n",
    "    # Obtener el Training Score (R² en el conjunto de entrenamiento)\n",
    "    train_scores.append(grb.score(X_train, y_train))\n",
    "\n",
    "    # Obtener el Testing Score (R² en el conjunto de prueba)\n",
    "    test_scores.append(grb.score(X_test, y_test))\n",
    "\n",
    "    # Calcular el puntaje promedio (usar negativo porque cross_val_score devuelve errores negativos)\n",
    "    scores.append(-1*np.mean(cv_scores))\n",
    "\n",
    "# Encontrar el valor de min_samples_split con el menor error\n",
    "best_n = 2 + np.argmin(scores)*47\n",
    "print(f\"Mejor valor de min_samples_split: {best_n}\")\n",
    "\n",
    "# Graficar los puntajes\n",
    "plt.plot(range_test, scores)\n",
    "plt.xlabel('Mínimo de muestras para partición (min_samples_split)')\n",
    "plt.ylabel('Error promedio (RMSE)')\n",
    "plt.title('Mínimo de muestras para partición vs. Error')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range_test, train_scores, label='Training Score (R²)', color='blue', marker='o')\n",
    "plt.plot(range_test, test_scores, label='Testing Score (R²)', color='green', marker='o')\n",
    "\n",
    "# Añadir etiquetas y título\n",
    "plt.xlabel('Mínimo de muestras para partición (min_samples_split)')\n",
    "plt.ylabel('Puntaje R²')\n",
    "plt.title('Training vs Testing Score en relación a min_samples_split')\n",
    "\n",
    "# Añadir la leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "range_test = range(1, 136, 5)\n",
    "\n",
    "# Probar diferentes valores de min_samples_leaf\n",
    "for n in range_test:\n",
    "    grb = GradientBoostingRegressor(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        min_samples_split=600,\n",
    "        min_samples_leaf=n,\n",
    "        max_depth=5,\n",
    "        random_state=42,\n",
    "        max_features='sqrt',\n",
    "    )\n",
    "    # Realizar cross-validation con 5 particiones (cv=5)\n",
    "    cv_scores = cross_val_score(grb, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    grb.fit(X_train, y_train)\n",
    "    # Obtener el Training Score (R² en el conjunto de entrenamiento)\n",
    "    train_scores.append(grb.score(X_train, y_train))\n",
    "\n",
    "    # Obtener el Testing Score (R² en el conjunto de prueba)\n",
    "    test_scores.append(grb.score(X_test, y_test))\n",
    "\n",
    "    # Calcular el puntaje promedio (usar negativo porque cross_val_score devuelve errores negativos)\n",
    "    scores.append(-1*np.mean(cv_scores))\n",
    "\n",
    "# Encontrar el valor de min_samples_leaf con el menor error\n",
    "best_n = 1 + np.argmin(scores)*5\n",
    "print(f\"Mejor valor de min_samples_leaf: {best_n}\")\n",
    "\n",
    "# Graficar los puntajes\n",
    "plt.plot(range_test, scores)\n",
    "plt.xlabel('Mínimo de muestras por hoja (min_samples_leaf)')\n",
    "plt.ylabel('Error promedio (RMSE)')\n",
    "plt.title('Mínimo de muestras por hoja vs. Error')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range_test, train_scores, label='Training Score (R²)', color='blue', marker='o')\n",
    "plt.plot(range_test, test_scores, label='Testing Score (R²)', color='green', marker='o')\n",
    "\n",
    "# Añadir etiquetas y título\n",
    "plt.xlabel('Mínimo de muestras por hoja (min_samples_leaf)')\n",
    "plt.ylabel('Puntaje R²')\n",
    "plt.title('Training vs Testing Score en relación a min_samples_leaf')\n",
    "\n",
    "# Añadir la leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "range_test = range(1, 28)\n",
    "\n",
    "# Probar diferentes valores de max_depth\n",
    "for n in range_test:\n",
    "    grb = GradientBoostingRegressor(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        min_samples_split=600,\n",
    "        min_samples_leaf=60,\n",
    "        max_depth=n,\n",
    "        random_state=42,\n",
    "        max_features='sqrt',\n",
    "    )\n",
    "    # Realizar cross-validation con 5 particiones (cv=5)\n",
    "    cv_scores = cross_val_score(grb, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    grb.fit(X_train, y_train)\n",
    "    # Obtener el Training Score (R² en el conjunto de entrenamiento)\n",
    "    train_scores.append(grb.score(X_train, y_train))\n",
    "\n",
    "    # Obtener el Testing Score (R² en el conjunto de prueba)\n",
    "    test_scores.append(grb.score(X_test, y_test))\n",
    "\n",
    "    # Calcular el puntaje promedio (usar negativo porque cross_val_score devuelve errores negativos)\n",
    "    scores.append(-1*np.mean(cv_scores))\n",
    "\n",
    "# Encontrar el valor de max_depth con el menor error\n",
    "best_n = np.argmin(scores) + 1\n",
    "print(f\"Mejor valor de max_depth: {best_n}\")\n",
    "\n",
    "# Graficar los puntajes\n",
    "plt.plot(range_test, scores)\n",
    "plt.xlabel('Máxima profundidad (max_depth)')\n",
    "plt.ylabel('Error promedio (RMSE)')\n",
    "plt.title('Máxima profundidad vs. Error')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range_test, train_scores, label='Training Score (R²)', color='blue', marker='o')\n",
    "plt.plot(range_test, test_scores, label='Testing Score (R²)', color='green', marker='o')\n",
    "\n",
    "# Añadir etiquetas y título\n",
    "plt.xlabel('Máxima profundidad (max_depth)')\n",
    "plt.ylabel('Puntaje R²')\n",
    "plt.title('Training vs Testing Score en relación a max_depth')\n",
    "\n",
    "# Añadir la leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grb = GradientBoostingRegressor(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=6,\n",
    "    max_depth=27,\n",
    "    random_state=42,\n",
    "    max_features='sqrt',\n",
    ")\n",
    "\n",
    "best_grb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_best_grb = best_grb.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "mse_best_grb = mean_squared_error(y_test, y_pred_best_grb)\n",
    "rmse_best_grb = root_mean_squared_error(y_test, y_pred_best_grb)\n",
    "r2_best_grb = r2_score(y_test, y_pred_best_grb)\n",
    "\n",
    "train_score_best_gbr = best_grb.score(X_train, y_train)\n",
    "\n",
    "test_score_best_gbr = best_grb.score(X_test, y_test)\n",
    "\n",
    "mae_best_grb = mean_absolute_error(y_test, y_pred_best_grb)\n",
    "print(f'Mean Squared Error (Mejor Gradient Boosting): {mse_best_grb}')\n",
    "print(f'Root Mean Squared Error (Mejor Gradient Boosting): {rmse_best_grb}')\n",
    "print(f'R² Score (Mejor Gradient Boosting): {r2_best_grb}')\n",
    "print(f\"Training Score (R²): {train_score_best_gbr}\")\n",
    "print(f\"Testing Score (R²): {test_score_best_gbr}\")\n",
    "print(f\"MAE: {mae_best_grb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la gráfica\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_best_grb, alpha=0.7, color='b', label='Predicciones')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, label='Limite de decisión')\n",
    "\n",
    "# Etiquetas y título\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Predicciones vs Valores Reales (Gradient Boosting)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "range_test = range(2, 28)\n",
    "\n",
    "# Probar diferentes valores de min_samples_split\n",
    "for n in range_test:\n",
    "    grb = GradientBoostingRegressor(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        min_samples_split=n,\n",
    "        min_samples_leaf=6,\n",
    "        max_depth=27,\n",
    "        random_state=42,\n",
    "        max_features='sqrt',\n",
    "    )\n",
    "    # Realizar cross-validation con 5 particiones (cv=5)\n",
    "    cv_scores = cross_val_score(grb, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    grb.fit(X_train, y_train)\n",
    "    # Obtener el Training Score (R² en el conjunto de entrenamiento)\n",
    "    train_scores.append(grb.score(X_train, y_train))\n",
    "\n",
    "    # Obtener el Testing Score (R² en el conjunto de prueba)\n",
    "    test_scores.append(grb.score(X_test, y_test))\n",
    "\n",
    "    # Calcular el puntaje promedio (usar negativo porque cross_val_score devuelve errores negativos)\n",
    "    scores.append(-1*np.mean(cv_scores))\n",
    "\n",
    "# Encontrar el valor de min_samples_split con el menor error\n",
    "best_n = 2 + np.argmin(scores)\n",
    "print(f\"Mejor valor de min_samples_split: {best_n}\")\n",
    "\n",
    "# Graficar los puntajes\n",
    "plt.plot(range_test, scores)\n",
    "plt.xlabel('Mínimo de muestras para partición (min_samples_split)')\n",
    "plt.ylabel('Error promedio (RMSE)')\n",
    "plt.title('Mínimo de muestras para partición vs. Error')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range_test, train_scores, label='Training Score (R²)', color='blue', marker='o')\n",
    "plt.plot(range_test, test_scores, label='Testing Score (R²)', color='green', marker='o')\n",
    "\n",
    "# Añadir etiquetas y título\n",
    "plt.xlabel('Mínimo de muestras para partición (min_samples_split)')\n",
    "plt.ylabel('Puntaje R²')\n",
    "plt.title('Training vs Testing Score en relación a min_samples_split')\n",
    "\n",
    "# Añadir la leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "range_test = range(1, 27)\n",
    "\n",
    "# Probar diferentes valores de min_samples_leaf\n",
    "for n in range_test:\n",
    "    grb = GradientBoostingRegressor(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=n,\n",
    "        max_depth=27,\n",
    "        random_state=42,\n",
    "        max_features='sqrt',\n",
    "    )\n",
    "    # Realizar cross-validation con 5 particiones (cv=5)\n",
    "    cv_scores = cross_val_score(grb, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    grb.fit(X_train, y_train)\n",
    "    # Obtener el Training Score (R² en el conjunto de entrenamiento)\n",
    "    train_scores.append(grb.score(X_train, y_train))\n",
    "\n",
    "    # Obtener el Testing Score (R² en el conjunto de prueba)\n",
    "    test_scores.append(grb.score(X_test, y_test))\n",
    "\n",
    "    # Calcular el puntaje promedio (usar negativo porque cross_val_score devuelve errores negativos)\n",
    "    scores.append(-1*np.mean(cv_scores))\n",
    "\n",
    "# Encontrar el valor de min_samples_leaf con el menor error\n",
    "best_n = 1 + np.argmin(scores)\n",
    "print(f\"Mejor valor de min_samples_leaf: {best_n}\")\n",
    "\n",
    "# Graficar los puntajes\n",
    "plt.plot(range_test, scores)\n",
    "plt.xlabel('Mínimo de muestras por hoja (min_samples_leaf)')\n",
    "plt.ylabel('Error promedio (RMSE)')\n",
    "plt.title('Mínimo de muestras por hoja vs. Error')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range_test, train_scores, label='Training Score (R²)', color='blue', marker='o')\n",
    "plt.plot(range_test, test_scores, label='Testing Score (R²)', color='green', marker='o')\n",
    "\n",
    "# Añadir etiquetas y título\n",
    "plt.xlabel('Mínimo de muestras por hoja (min_samples_leaf)')\n",
    "plt.ylabel('Puntaje R²')\n",
    "plt.title('Training vs Testing Score en relación a min_samples_leaf')\n",
    "\n",
    "# Añadir la leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "range_test = range(1, 28)\n",
    "\n",
    "# Probar diferentes valores de max_depth\n",
    "for n in range_test:\n",
    "    grb = GradientBoostingRegressor(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=6,\n",
    "        max_depth=n,\n",
    "        random_state=42,\n",
    "        max_features='sqrt',\n",
    "    )\n",
    "    # Realizar cross-validation con 5 particiones (cv=5)\n",
    "    cv_scores = cross_val_score(grb, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    grb.fit(X_train, y_train)\n",
    "    # Obtener el Training Score (R² en el conjunto de entrenamiento)\n",
    "    train_scores.append(grb.score(X_train, y_train))\n",
    "\n",
    "    # Obtener el Testing Score (R² en el conjunto de prueba)\n",
    "    test_scores.append(grb.score(X_test, y_test))\n",
    "\n",
    "    # Calcular el puntaje promedio (usar negativo porque cross_val_score devuelve errores negativos)\n",
    "    scores.append(-1*np.mean(cv_scores))\n",
    "\n",
    "# Encontrar el valor de max_depth con el menor error\n",
    "best_n = np.argmin(scores) + 1\n",
    "print(f\"Mejor valor de max_depth: {best_n}\")\n",
    "\n",
    "# Graficar los puntajes\n",
    "plt.plot(range_test, scores)\n",
    "plt.xlabel('Máxima profundidad (max_depth)')\n",
    "plt.ylabel('Error promedio (RMSE)')\n",
    "plt.title('Máxima profundidad vs. Error')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range_test, train_scores, label='Training Score (R²)', color='blue', marker='o')\n",
    "plt.plot(range_test, test_scores, label='Testing Score (R²)', color='green', marker='o')\n",
    "\n",
    "# Añadir etiquetas y título\n",
    "plt.xlabel('Máxima profundidad (max_depth)')\n",
    "plt.ylabel('Puntaje R²')\n",
    "plt.title('Training vs Testing Score en relación a max_depth')\n",
    "\n",
    "# Añadir la leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medición de Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "best_grb = GradientBoostingRegressor(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=6,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    max_features='sqrt',\n",
    ")\n",
    "\n",
    "tracemalloc.start()\n",
    "# Entrenar el modelo\n",
    "def train_model_gbr():\n",
    "    best_grb.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "def predict_model_gbr():\n",
    "    global y_pred_best_grb\n",
    "    y_pred_best_grb = best_grb.predict(X_test)\n",
    "\n",
    "\n",
    "train_time_gbr = timeit.timeit(train_model_gbr, number=1)\n",
    "print(f\"Tiempo de entrenamiento: {train_time_gbr:.2f} segundos\")\n",
    "\n",
    "\n",
    "predict_time_gbr = timeit.timeit(predict_model_gbr, number=1)\n",
    "print(f\"Tiempo de predicción: {predict_time_gbr:.2f} segundos\")\n",
    "\n",
    "memoria_gbr, peak_gbr = tracemalloc.get_traced_memory()\n",
    "print(f\"Uso de memoria actual: {memoria_gbr / 10**6:.2f} MB\")\n",
    "print(f\"Pico de uso de memoria: {peak_gbr / 10**6:.2f} MB\")\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "mse_best_grb = mean_squared_error(y_test, y_pred_best_grb)\n",
    "rmse_best_grb = root_mean_squared_error(y_test, y_pred_best_grb)\n",
    "r2_best_grb = r2_score(y_test, y_pred_best_grb)\n",
    "\n",
    "train_score_best_gbr = best_grb.score(X_train, y_train)\n",
    "\n",
    "test_score_best_gbr = best_grb.score(X_test, y_test)\n",
    "\n",
    "mae_best_grb = mean_absolute_error(y_test, y_pred_best_grb)\n",
    "\n",
    "print(f'Mean Squared Error (Mejor Gradient Boosting): {mse_best_grb}')\n",
    "print(f'Root Mean Squared Error (Mejor Gradient Boosting): {rmse_best_grb}')\n",
    "print(f'R² Score (Mejor Gradient Boosting): {r2_best_grb}')\n",
    "print(f\"Training Score (R²): {train_score_best_gbr}\")\n",
    "print(f\"Testing Score (R²): {test_score_best_gbr}\")\n",
    "print(f\"MAE: {mae_best_grb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafican los resultados obtenidos:\n",
    "# Valores de R²\n",
    "scores = [train_score_best_gbr, test_score_best_gbr]\n",
    "labels = ['Training Score', 'Testing Score']\n",
    "\n",
    "# Convertir a porcentaje\n",
    "scores_percentage = [score * 100 for score in scores]\n",
    "\n",
    "# Crear gráfico de barras\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(labels, scores_percentage, color=['blue', 'orange'])\n",
    "plt.ylim(0, 100)  # Rango de porcentaje\n",
    "plt.ylabel('R² Score (%)')\n",
    "plt.title('Comparación de R² Scores')\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "\n",
    "# Formatear etiquetas en el eje y como porcentaje\n",
    "plt.yticks(ticks=np.arange(0, 101, 10), labels=[f'{int(tick)}%' for tick in np.arange(0, 101, 10)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la gráfica\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_best_grb, alpha=0.7, color='b', label='Predicciones')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, label='Limite de decisión')\n",
    "\n",
    "# Etiquetas y título\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Predicciones vs Valores Reales (Gradient Boosting)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarking\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Crear el DataFrame con las métricas de los modelos\n",
    "benchmark = pd.DataFrame({\n",
    "    \"MSE\": [mse_knn_final, mse_rf, mse_best_grb],\n",
    "    \"RMSE\": [rmse_knn_final, rmse_rf, rmse_best_grb],\n",
    "    \"R²\": [r2_knn_final, r2_rf, r2_best_grb],\n",
    "    \"Train R²\": [train_score_knn_final, train_score_rf, train_score_best_gbr],\n",
    "    \"Test R²\": [test_score_knn_final, test_score_rf, test_score_best_gbr],\n",
    "    \"MAE\": [mae_knn_final, mae_bayeciana_rf, mae_best_grb]\n",
    "}, index=[\"KNN\", \"Random Forest\", \"Gradient Boosting\"])\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def truncate(value, decimals=3):\n",
    "    factor = 10 ** decimals\n",
    "    return int(value * factor) / factor\n",
    "\n",
    "benchmark_train_test = benchmark[['Train R²', 'Test R²']]\n",
    "# Gráfico de barras para comparar todos los modelos\n",
    "ax = benchmark_train_test.plot(kind=\"bar\", figsize=(12, 6), title=\"Benchmarking de Modelos\")\n",
    "plt.ylabel(\"Valores\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "# Agregar los valores encima de las barras\n",
    "for p in ax.patches:\n",
    "    value = truncate(p.get_height(), 3)  # Truncar a 2 decimales\n",
    "    ax.annotate(\n",
    "        f'{value}',  # Mostrar el valor truncado\n",
    "        (p.get_x() + p.get_width() / 2, p.get_height()),\n",
    "        ha='center', va='bottom', fontsize=10\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_RMSE = benchmark[['RMSE']]\n",
    "\n",
    "ax2 = benchmark_RMSE.plot(kind=\"bar\", color=[\"blue\", \"green\", \"red\"], figsize=(8, 5), title=\"Comparación de RMSE\")\n",
    "# Lista de colores personalizados (uno para cada barra)\n",
    "colors = [ \"purple\", \"green\", \"orange\"]  # Expande según el número de barras\n",
    "\n",
    "# Asignar colores a las barras, esto lo hago ya que de forma predeterminada, como todos son RMSE; todos salen en azul\n",
    "for i, bar in enumerate(ax2.patches):  # Recorrer las barras\n",
    "    bar.set_color(colors[i % len(colors)])  # Asignar color de forma cíclica\n",
    "\n",
    "\n",
    "plt.ylabel(\"Root Mean Absolute Error\")\n",
    "plt.xticks(rotation=0)\n",
    "ax2.legend().remove() # Como le cambié el color a las barras, la elimino, ya que no coincide con los colores\n",
    "# Agregar los valores encima de las barras\n",
    "for p in ax2.patches:\n",
    "    \n",
    "    ax2.annotate(\n",
    "        f'{p.get_height():.2f}',  # Valor con 2 decimales\n",
    "        (p.get_x() + p.get_width() / 2, p.get_height()),\n",
    "        ha='center', va='bottom', fontsize=10\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "models = ['KNN', 'Random Forest',  'Gradient Boosting']\n",
    "train_times = [train_time_knn, train_time_rf, train_time_gbr]\n",
    "predict_times = [predict_time_knn, predict_time_rf, predict_time_gbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el gráfico de barras\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "width = 0.35\n",
    "x = np.arange(len(models))\n",
    "\n",
    "bars_train = ax.bar(x - width/2, train_times, width, label='Train Time', color='blue')\n",
    "bars_predict = ax.bar(x + width/2, predict_times, width, label='Predict Time', color='orange')\n",
    "\n",
    "# Etiquetas y leyenda\n",
    "ax.set_xlabel('Modelos', fontsize=12)\n",
    "ax.set_ylabel('Tiempo (segundos)', fontsize=12)\n",
    "ax.set_title('Comparación de Tiempos: Entrenamiento vs Predicción', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "\n",
    "# Agregar valores encima de las barras\n",
    "for bar in bars_train + bars_predict:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.2f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Datos en bytes convertidos a MB\n",
    "models = ['KNN', 'Random Forest', 'Gradient Boosting']\n",
    "memoria = [memoria_knn / 1e6, memoria_rf / 1e6, memoria_gbr / 1e6]  # Conversión a MB\n",
    "peak = [peak_knn / 1e6, peak_rf / 1e6, peak_gbr / 1e6]  # Conversión a MB\n",
    "\n",
    "# Configuración del gráfico\n",
    "x = np.arange(len(models))  # Posiciones en el eje X\n",
    "width = 0.25  # Ancho de las barras\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars_memoria = ax.bar(x - width/2, memoria, width, label='Memoria (MB)', color='blue')\n",
    "bars_peak = ax.bar(x + width/2, peak, width, label='Pico de Memoria (MB)', color='orange')\n",
    "\n",
    "# Etiquetas y títulos\n",
    "ax.set_xlabel('Modelos', fontsize=12)\n",
    "ax.set_ylabel('Memoria (MB)', fontsize=12)\n",
    "ax.set_title('Comparación de Uso de Memoria y Pico de Memoria por Modelo', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "\n",
    "# Agregar valores encima de las barras\n",
    "for bar in bars_memoria + bars_peak:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.2f} MB',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Datos en bytes convertidos a MB\n",
    "models = ['KNN', 'Random Forest', 'Gradient Boosting']\n",
    "memoria = [memoria_knn / 1e6, memoria_rf / 1e6, memoria_gbr / 1e6]  # Conversión a MB\n",
    "peak = [peak_knn / 1e6, peak_rf / 1e6, peak_gbr / 1e6]  # Conversión a MB\n",
    "\n",
    "x_labels = ['Memoria', 'Pico de Memoria']\n",
    "data = np.array([memoria, peak]).T  # Transponer para representar modelos en filas\n",
    "\n",
    "# Crear el gráfico\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    ax.plot(x_labels, data[i], marker='o', label=model)  # Una línea por modelo\n",
    "\n",
    "# Etiquetas y leyendas\n",
    "ax.set_xlabel('Tipo de Métrica', fontsize=12)\n",
    "ax.set_ylabel('Memoria (MB)', fontsize=12)\n",
    "ax.set_title('Comparación de Uso de Memoria y Pico de Memoria por Modelo', fontsize=14)\n",
    "ax.legend(title=\"Modelos\")\n",
    "\n",
    "# Agregar valores encima de los puntos, esto con el objetivo de poder ver correctamente las diferencias\n",
    "for i, model in enumerate(models):\n",
    "    for j, value in enumerate(data[i]):\n",
    "        ax.annotate(f'{value:.2f} MB',\n",
    "                    xy=(x_labels[j], value),\n",
    "                    textcoords=\"offset points\",\n",
    "                    xytext=(0, 10),\n",
    "                    ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
